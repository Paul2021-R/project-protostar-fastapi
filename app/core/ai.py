import os
import glob
from typing import List, Optional
from openai import AsyncOpenAI
from core.config import settings

GLOBAL_SYSTEM_PROMPT: str = ''
GLOBAL_KNOWLEDGE_BASE: str = '' 

# 1. OpenRouter í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# Base URLì„ ë°˜ë“œì‹œ 'https://openrouter.ai/api/v1'ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•¨
client = AsyncOpenAI(
    api_key=settings.OPENROUTER_API_KEY,
    base_url="https://openrouter.ai/api/v1",
    # [ê¶Œì¥] OpenRouterì— ë‚´ ì•± ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” í—¤ë”
    default_headers={
        "HTTP-Referer": settings.SITE_URL, 
        "X-Title": settings.SITE_NAME,
    }
)

def read_markdown_files(directory: str) -> str:
    """
    ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  md íŒŒì¼ì„ ì°¾ì•„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
    """
    combined_text = []
    file_paths = glob.glob(os.path.join(directory, "*.md"))
    file_paths.sort()

    for file_path in file_paths:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read().strip()
                filename = os.path.basename(file_path)
                combined_text.append(f"### [Source: {filename}]\n{content}")
        
        except Exception as e:
            print(f"âš ï¸ Failed to read {file_path}: {e}")
    return "\n\n".join(combined_text)

async def init_ai_context():
    """
    ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œí•˜ì—¬ ì „ì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ 
    """

    global GLOBAL_SYSTEM_PROMPT
    global GLOBAL_KNOWLEDGE_BASE

    base_dir = "prompts"
    # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    print(f"ğŸ“‚ Loading System Prompts from {base_dir}/system/...")
    system_text = read_markdown_files(os.path.join(base_dir, "system"))
    if system_text:
        GLOBAL_SYSTEM_PROMPT = system_text
        print(f"âœ… System Prompt Loaded ({len(GLOBAL_SYSTEM_PROMPT)} chars)")
    else:
        print("âš ï¸ No system prompts found. Using default.")
    
    # 2. ì§€ì‹ ë°ì´í„° ë¡œë“œ 
    print(f"ğŸ“‚ Loading User Data from {base_dir}/user_data/...")
    knowledge_text = read_markdown_files(os.path.join(base_dir, "user_data"))
    if knowledge_text:
        GLOBAL_KNOWLEDGE_BASE = knowledge_text
        print(f"âœ… Knowledge Base Loaded ({len(GLOBAL_KNOWLEDGE_BASE)} chars)")
    else:
        print("â„¹ï¸ No user data found.")


async def generate_response(prompt: str, context: str = ''):
    """
    ë¡œë“œëœ ì „ì—­ ë³€ìˆ˜ë“¤ì„ í™œìš©í•˜ì—¬ ê¸°ë³¸ ë‹µë³€ì„ ìƒì„±í•´ë‚¸ë‹¤.
    """

    if not context:
        full_user_content = f"""

        You are an intelligent assistant named "Protostar".
        Answer the user's question based ONLY on the provided context below.
        
        <instruction>
        Answer the following question based on the context above.
        If the answer is not in the context, strictly say "I don't know based on the provided documents."
        Do not halluciation or generate external information.
        </instruction>

        <question>
        {prompt}
        </question>

        <context>
        {GLOBAL_KNOWLEDGE_BASE}
        </context>
        """
    else: 
        full_user_content = f"""

        You are an intelligent assistant named "Protostar".
        Answer the user's question based ONLY on the provided context below.
        
        <instruction>
        Answer the following question based on the context above.
        If the answer is not in the context, strictly say "I don't know based on the provided documents."
        Do not halluciation or generate external information.
        </instruction>

        <question>
        {prompt}
        </question>

        <context>
        {context}

        {GLOBAL_KNOWLEDGE_BASE}
        </context>
        """

    try:
        # 2. ë¹„ë™ê¸° í˜¸ì¶œ (Standard OpenAI Format)
        response = await client.chat.completions.create(
            model=settings.OPENROUTER_MODEL,
            messages=[
                {"role": "system", "content": GLOBAL_SYSTEM_PROMPT},
                {"role": "user", "content": full_user_content}
            ],
            temperature=0.3,
        )
        
        # 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        return response.choices[0].message.content
        
    except Exception as e:
        return f"âŒ OpenRouter Error: {str(e)}"