import logging
from sqlalchemy import select
from core.database import AsyncSessionLocal
from core.vectorized_doc import VectorizedDoc 
from core.worker_knowledge import get_embeddings # ì„ë² ë”© í•¨ìˆ˜ ì¬ì‚¬ìš©, ë‚˜ì¤‘ì— AI ìª½ ë¦¬í™í† ë§ í•„ìš”

logger = logging.getLogger("uvicorn")

async def search_similar_docs(query: str, top_k: int = 3):
  """
  ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ DB ì—ì„œ ê²€ìƒ‰ (Cosine Similarity)
  """

  try:
    # 1 ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜ 
    query_vectors = await get_embeddings([query])
    
    if not query_vectors:
      logger.warning("âš ï¸ Failed to generate embedding for query.")
      return []
    
    query_embedding = query_vectors[0]

    async with AsyncSessionLocal() as db:
      stmt = (
        select(VectorizedDoc)
        .order_by(VectorizedDoc.embedding.cosine_distance(query_embedding))
        .limit(top_k)
      )

      result = await db.execute(stmt)
      docs = result.scalars().all()
      
      logger.info(f"ğŸ” RAG Search found {len(docs)} docs for: '{query}'")
      return docs

  except Exception as e:
    logger.error(f"âŒ Search Similar Docs Error: {e}")
    raise e

def format_rag_context(docs: list[VectorizedDoc]) -> str:
  """
  ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ LLM í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
  """

  if not docs:
    return ""

  context_list = []
  for i, doc in enumerate(docs):
    meta = doc.meta_data if doc.meta_data else {}
    keywords = ", ".join(meta.get('keywords', [])) 
    summary = meta.get('summary', 'No summary')

    source_block = f"""
    [Document #{i+1}]
    - Keywords: {keywords}
    - Summary: {summary}
    - Content:
    {doc.content}
    """

    context_list.append(source_block)
    
  return "\n\n--\n\n".join(context_list)
