import asyncio
import json
import logging
import uuid
from datetime import datetime
from core.config import settings

# ê¸°ì¡´ Import
from core.redis import get_redis_client
from core.ai import generate_response_stream

# DB ë° ì„œë¹„ìŠ¤ Import
from core.database import AsyncSessionLocal 
from core.services import save_user_message, save_initial_response, get_session_history
from .models import Message, MessageRole, ProcessingStatus
from core.rag_service import search_similar_docs, format_rag_context


logger = logging.getLogger("uvicorn")

TARGET_TPS = 100
TEST_DELAY = 1 / TARGET_TPS

MAX_CONCURRENT_JOBS = 100
semaphore = asyncio.Semaphore(MAX_CONCURRENT_JOBS)

async def process_chat_job(job_id: str, redis_client): 
    """
    ë‹¨ì¼ ì±„íŒ… ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ 
    1. Redis ì—ì„œ ì‘ì—… ë°ì´í„° ì¡°íšŒ
    2. ìµœì´ˆ ì§ˆë¬¸ ì €ì¥
    3. AI ì‘ë‹µ ìƒì„± (ì´ë•Œ ì „ì²´ ëŒ€í™” íë¦„ í•¨ê»˜ ë“¤ì–´ê°)
    4. ë‹µë³€ ì €ì¥
    5. Redis Pub/Sub ì— ê²°ê³¼ ì „ì†¡
    6. AI ì‘ë‹µì˜ ìš”ì•½ ìƒì„± ë° ì €ì¥ 
    """

    # ì‘ì—… í‚¤ í™•ë³´
    task_key = f"chat:task:{job_id}"

    # async with AsyncSessionLocal() as db:
    try:
        # ì‘ì—… ë°ì´í„° ë°ì´í„° ì¡°íšŒ
        task_data_json = await redis_client.get(task_key)

        if not task_data_json:
            logger.warning(f"Task data missing for job: {job_id}")
            return

        # ì‘ì—… ë°ì´í„° íŒŒì‹±   
        task_data = json.loads(task_data_json)

        mode = task_data.get("mode")
        session_id = task_data.get("sessionId")
        raw_user_uuid = task_data.get("uuid")
        try:
            user_uuid = uuid.UUID(raw_user_uuid)
        except ValueError:
            logger.error(f"âŒ Invalid UUID format: {raw_user_uuid}")
            return # í˜¹ì€ ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§

        prompt = task_data.get("content")
        base_context = task_data.get("context", "")

        timestamp = task_data.get("timestamp")

        logger.info(f"ğŸ¤– Processing Job {job_id} | User: {raw_user_uuid} | Session: {session_id}")

        # RAG ê²€ìƒ‰ ë¡œì§
        rag_system_message=""

        if mode in ['general']:
            logger.info(f"ğŸ” [RAG] Searching docs for: '{prompt}'")
            found_docs = await search_similar_docs(prompt)

            if found_docs:
                rag_context_str = format_rag_context(found_docs)
                rag_system_message = f"""
You are an intelligent assistant named Protostar.

[Instructions]
- Use the provided [Retrieved Knowledge] to answer the user's question accurately.
- If the answer is found in the knowledge, cite the source keywords if possible.
- If the answer is NOT in the knowledge, rely on your general knowledge but mention that "This information is not in the provided documents."
- Respond in the same language as the user's question (Korean).

[Retrieved Knowledge]
{rag_context_str}
"""         
                logger.info("âœ… [RAG] Context injected into system prompt.")
            else:
                logger.info("âš ï¸ [RAG] No relevant documents found.")    

        final_system_context = f"{rag_system_message}\n\n{base_context}".strip()                
        
        user_msg = None

        # ì‚¬ìš©ì ì§ˆë¬¸ DB ì €ì¥ 
        async with AsyncSessionLocal() as db:
            try: 
                user_msg = await save_user_message(
                    db,
                    user_uuid,
                    session_id,
                    prompt,
                )
                user_msg_id = user_msg.id
            except Exception as e:
                logger.error(f"âŒ Error saving user message: {e}")
                raise e

        channel = f"chat:stream:{raw_user_uuid}-{session_id}"

        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        if mode not in ['general', 'page_context']:
            test_message_payload = {
                "type": 'message',
                "content": "T",
                "uuid": raw_user_uuid,
                "sessionId": session_id,
                "timestamp": task_data.get("timestamp")
            }
            await redis_client.publish(channel, json.dumps(test_message_payload))

            await asyncio.sleep(TEST_DELAY) 

            done_payload = {
                "type": 'done',
                "content": 'done',
                "uuid": raw_user_uuid,
                "sessionId": session_id,
                "timestamp": task_data.get("timestamp")
            }
            
            await redis_client.publish(channel, json.dumps(done_payload))
            await redis_client.delete(task_key)
            logger.info(f"ğŸ—‘ï¸ [Test] Deleted task data for job: {job_id}")
            return


        history_context = []
        if user_msg:
            async with AsyncSessionLocal() as db:
                past_messages = await get_session_history(
                    db,
                    session_id,
                    exclude_ids=[user_msg_id]
                )
                for msg in past_messages:
                    final_content = msg.content_summary if msg.content_summary else msg.content_full

                    role = "assistant" if msg.role == MessageRole.ASSISTANT else "user"

                    history_context.append({
                        "role": role,
                        "content": final_content,
                    })
        # AIê°€ í•œ í† í°(ì¡°ê°)ë¥¼ ì¤„ ë•Œë§ˆë‹¤ Redisë¡œ ì¦‰ì‹œ ë°œì†¡
        # í† í° ìˆ˜ì§‘ ì¤€ë¹„
        full_response_list = []
        
        async for token in generate_response_stream(
            prompt, 
            mode, 
            final_system_context, 
            history=history_context
            ):
            full_response_list.append(token)
            message_payload = {
                "type": 'message',
                "content": token, # ì „ì²´ ë¬¸ì¥ì´ ì•„ë‹Œ 'ì¡°ê°'
                "uuid": raw_user_uuid,
                "sessionId": session_id,
                "timestamp": task_data.get("timestamp")
            }
            # print(token)
            # NestJSë¡œ ì¡°ê° ë°œì†¡
            await redis_client.publish(channel, json.dumps(message_payload))

        done_payload = {
            "type": 'done',            # ì™„ë£Œ íƒ€ì… (NestJSë‚˜ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‹ë³„ ê°€ëŠ¥)
            "content": 'done',           # ë‚´ìš©ì€ ì—†ìŒ
            "uuid": raw_user_uuid,
            "sessionId": session_id,
            "timestamp": datetime.now().isoformat()
        }
        await redis_client.publish(channel, json.dumps(done_payload))
        logger.info(f"âœ… Job {job_id} Finished & DONE signal sent.")

        # ë‹µë³€ DB 1ì°¨ ì €ì¥ 
        full_response_text = "".join(full_response_list)
        usage_data = {
            "input": len(prompt),
            "output": len(full_response_text),
            "model": settings.OPENROUTER_MODEL
        }
        async with AsyncSessionLocal() as db:
            try:
                saved_msg = await save_initial_response(
                    db,
                    user_uuid,
                    session_id,
                    full_response_text,
                    usage_data,
                )
                logger.info(f"ğŸ’¾ Saved AI Response. MsgID: {saved_msg.id}")

                await redis_client.rpush("chat:summary:queue", str(saved_msg.id))
                logger.info(f"ğŸ”” Triggered Summary for MsgID: {saved_msg.id}")

            except Exception as e:
                logger.error(f"âš ï¸ AI response save failed: {e}")

        await redis_client.delete(task_key)
        logger.info(f"ğŸ—‘ï¸ Deleted task data for job: {job_id}")
        
    except Exception as e:
        # DLQ êµ¬í˜„ 
        # Promtail ë¡œ ì¶”ì  ì¤‘ì´ë‹ˆ ì‹ë³„ìë¥¼ í¬í•¨í•œ JSON ì‹ì˜ ì¶œë ¥ êµ¬í˜„ 
        error_payload = {
            "type": "DLQ",
            "status": "failed",
            "job_id": job_id,
            "error_msg": str(e),
            "original_task_data": task_data if 'task_data' in locals() else None,
            "timestamp": datetime.now().isoformat()
        }
        logger.error(json.dumps(error_payload, ensure_ascii=False))
        logger.error(f"âŒ Error processing job {job_id}: {e}")  # ê¸°ì¡´ ì—ëŸ¬ í•¸ë“¤ë§, ê°„ë‹¨í•œ íŒë‹¨ìš©

async def run_worker():
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ë©° Redis Queue(chat:job:queue)ë¥¼ ì§€ì†ì ìœ¼ë¡œ í™•ì¸í•˜ëŠ” ë£¨í”„ 
    """
    logger.info("ğŸš€ Protostar Worker started. Listening to 'chat:job:queue'...")
    redis_client = get_redis_client()
    
    try:
        while True:

            await semaphore.acquire()
            
            result = await redis_client.brpop("chat:job:queue", timeout=5)

            if result:
                _, job_id = result 
                task = asyncio.create_task(process_chat_job(job_id, redis_client))
                task.add_done_callback(lambda t: semaphore.release())
            else:
                semaphore.release()
                await asyncio.sleep(0.0001)
    
    except asyncio.CancelledError:
        logger.info("ğŸ›‘ Worker loop cancelled.")
    except Exception as e:
        logger.error(f"âŒ Worker crashed: {e}")
    finally:
        await redis_client.close()
            